{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLjnyaPUvmoP"
      },
      "source": [
        "# Objective\n",
        "\n",
        "Given a list of embeddings, create and deploy a Vertex AI Vector Search (fka Matching Engine) index.\n",
        "\n",
        "Assumes you already have embeddings in GCS in a format supported by Vertex AI Vector Search. For instructions on that see:\n",
        "1. [Notebook](https://source.corp.google.com/piper///depot/google3/experimental/genaisa/product_catalog/notebooks/0_generate_multimodal_embeddings.ipynb) for generating multimodal embeddings and storing in BQ  \n",
        "2. [Saved query](https://pantheon.corp.google.com/bigquery?ws=!1m7!1m6!12m5!1m3!1ssolutions-2023-mar-107!2sus-central1!3s1b67da64-ecbc-42d6-945b-5fe1df4e559f!2e1) used to convert embeddings stored in BQ into vector search ingestion format. The product does not yet support direct import from BQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bki6-SfNUa9d"
      },
      "outputs": [],
      "source": [
        "!pip install google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvYq_G2GOdpD"
      },
      "source": [
        "---\n",
        "\n",
        "#### ⚠️ Do not forget to click the \"RESTART RUNTIME\" button above.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHdQoCb-6B35"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import auth as google_auth\n",
        "    google_auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N94ih12H6BFJ"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = 'solutions-2023-mar-107'\n",
        "REGION = 'us-central1'\n",
        "BUCKET_URI = 'gs://vector_search_regional/mercari_multimodal_embeddings/' # WHERE EMBEDDINGS ARE STORED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAA8polfUduJ"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBwMXLbTwvSe"
      },
      "source": [
        "# Create Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjDHVriifVdL"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name='mercari_multimodal_batch_tree_cosine',\n",
        "    contents_delta_uri=BUCKET_URI,\n",
        "    dimensions=1408,\n",
        "    approximate_neighbors_count=150,\n",
        "    distance_measure_type=\"COSINE_DISTANCE\",\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        "    description='Based on ~13K mercari product listings for which we have both a description and image',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ysk4-0FRp5l"
      },
      "outputs": [],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "print(INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiZQnbIU4Dzt"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDwzD5cRxDUf"
      },
      "source": [
        "# Deploy Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiloYESZ1FTE"
      },
      "outputs": [],
      "source": [
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name='mercari_Q3',\n",
        "    description='Endpoint for Q3 development on mercari',\n",
        "    public_endpoint_enabled=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otALXzzV3wYA"
      },
      "outputs": [],
      "source": [
        "DEPLOYED_INDEX_ID = 'muiltimodal_13K'\n",
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
        ")\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G7XWHr90WPi"
      },
      "source": [
        "# Query Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRI2Dh0h4y88"
      },
      "outputs": [],
      "source": [
        "#TODO move this code to a module\n",
        "import base64\n",
        "from google.cloud import aiplatform\n",
        "from google.protobuf import struct_pb2\n",
        "from functools import cache\n",
        "import time\n",
        "import typing\n",
        "\n",
        "\n",
        "# Inspired from https://stackoverflow.com/questions/34269772/type-hints-in-namedtuple.\n",
        "class EmbeddingResponse(typing.NamedTuple):\n",
        "  text_embedding: typing.Sequence[float]\n",
        "  image_embedding: typing.Sequence[float]\n",
        "\n",
        "\n",
        "class EmbeddingPredictionClient:\n",
        "  \"\"\"Wrapper around Prediction Service Client.\"\"\"\n",
        "  def __init__(self, project : str,\n",
        "    location : str = \"us-central1\",\n",
        "    api_regional_endpoint: str = \"us-central1-aiplatform.googleapis.com\"):\n",
        "    client_options = {\"api_endpoint\": api_regional_endpoint}\n",
        "    # Initialize client that will be used to create and send requests.\n",
        "    # This client only needs to be created once, and can be reused for multiple requests.\n",
        "    self.client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
        "    self.location = location\n",
        "    self.project = project\n",
        "\n",
        "  def get_embedding(self, text : str = None, image_path : str = None):\n",
        "    \"\"\"image_path can be a local path or a GCS URI.\"\"\"\n",
        "    if not text and not image_path:\n",
        "      raise ValueError('At least one of text or image_bytes must be specified.')\n",
        "\n",
        "    instance = struct_pb2.Struct()\n",
        "    if text:\n",
        "      instance.fields['text'].string_value = text\n",
        "\n",
        "    if image_path:\n",
        "      image_struct = instance.fields['image'].struct_value\n",
        "      if image_path.lower().startswith('gs://'):\n",
        "        image_struct.fields['gcsUri'].string_value = image_path\n",
        "      else:\n",
        "        with open(image_path, \"rb\") as f:\n",
        "          image_bytes = f.read()\n",
        "        encoded_content = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "        image_struct.fields['bytesBase64Encoded'].string_value = encoded_content\n",
        "\n",
        "    instances = [instance]\n",
        "    endpoint = (f\"projects/{self.project}/locations/{self.location}\"\n",
        "      \"/publishers/google/models/multimodalembedding@001\")\n",
        "    response = self.client.predict(endpoint=endpoint, instances=instances)\n",
        "\n",
        "    text_embedding = None\n",
        "    if text:\n",
        "      text_emb_value = response.predictions[0]['textEmbedding']\n",
        "      text_embedding = [v for v in text_emb_value]\n",
        "\n",
        "    image_embedding = None\n",
        "    if image_path:\n",
        "      image_emb_value = response.predictions[0]['imageEmbedding']\n",
        "      image_embedding = [v for v in image_emb_value]\n",
        "\n",
        "    return EmbeddingResponse(\n",
        "      text_embedding=text_embedding,\n",
        "      image_embedding=image_embedding)\n",
        "\n",
        "@cache\n",
        "def get_client(project):\n",
        "  return EmbeddingPredictionClient(project)\n",
        "\n",
        "\n",
        "def embed(project,text,image_path=None):\n",
        "  client = get_client(project)\n",
        "  start = time.time()\n",
        "  response = client.get_embedding(text=text, image_path=image_path)\n",
        "  end = time.time()\n",
        "  print('Embedding Time: ', end - start)\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToeQkiIqNMIa"
      },
      "outputs": [],
      "source": [
        "res = embed(PROJECT_ID,\n",
        "            'IZOD Women\\'s Light Gray Thigh Length Pull On Golf Shorts',\n",
        "            'gs://genai-product-catalog/toy_images/shorts.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRCnFT4B0jnm"
      },
      "outputs": [],
      "source": [
        "NUM_NEIGHBORS = 5\n",
        "\n",
        "response = my_index_endpoint.find_neighbors(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=[res.text_embedding,res.image_embedding],\n",
        "    num_neighbors=NUM_NEIGHBORS,\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV-TfD01RyrD"
      },
      "source": [
        "# Future Improvements\n",
        "\n",
        "1. Use streaming mode to enable fast updates. Doesn't seem to be exposed in python client.\n",
        "2. Take advantage of filtering option. Add filters for top level category and embedding type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CGlGZ0n3Yad"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
